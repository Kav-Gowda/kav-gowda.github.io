<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Portfolio</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- Global styles -->
  <link rel="stylesheet" href="style.css" />

  <style>
    /* =========================
       PAGE LAYOUT
       ========================= */

    body.portfolio-page {
      overflow-y: auto;
    }

    main.portfolio-page {
      max-width: 900px;
      margin: 0 auto;
      padding: 160px 20px 120px; /* space below fixed nav */
    }

    /* =========================
       SECTION STYLES
       ========================= */

    .portfolio-section {
      margin-bottom: 120px;
    }

    .portfolio-section h2 {
      font-family: "Cinzel", serif;
      font-size: 34px;
      color: #4a3b78;
      margin-bottom: 12px;
    }

    .portfolio-section .subtitle {
      font-size: 15px;
      font-style: italic;
      color: #5b4b8a;
      margin-bottom: 40px;
    }

    .portfolio-section h3 {
      font-size: 18px;
      font-weight: 600;
      margin-top: 48px;
      margin-bottom: 12px;
      color: #2b2b2b;
      font-family: system-ui, -apple-system, BlinkMacSystemFont,
                   "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    }

    .portfolio-section p {
      font-size: 16px;
      line-height: 1.75;
      color: #2b2b2b;
      margin-bottom: 16px;
      font-family: system-ui, -apple-system, BlinkMacSystemFont,
                   "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    }

    .portfolio-section ul {
      margin-left: 20px;
      margin-top: 12px;
    }

    .portfolio-section li {
      font-size: 16px;
      line-height: 1.7;
      margin-bottom: 8px;
      font-family: system-ui, -apple-system, BlinkMacSystemFont,
                   "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
    }

    .divider {
      margin-top: 64px;
      height: 1px;
      background: rgba(0, 0, 0, 0.08);
    }

    /* =========================
       MOBILE
       ========================= */

    @media (max-width: 768px) {
      main.portfolio-page {
        padding: 120px 16px 96px;
      }

      .portfolio-section h2 {
        font-size: 28px;
      }
    }
  </style>
</head>

<body class="portfolio-page">

  <!-- Mobile nav -->
  <button class="hamburger" id="hamburger">☰</button>

  <aside class="mobile-menu" id="mobileMenu">
    <button class="close" id="closeMenu">×</button>
    <a href="index.html">Home</a>
    <a href="resume.html">Resume</a>
    <a href="portfolio.html">Portfolio</a>
    <a href="achievements.html">Achievements</a>
    <a href="contact.html">Contact</a>
  </aside>

  <!-- Desktop nav -->
  <nav class="desktop-nav">
    <a href="index.html">Home</a>
    <a href="resume.html">Resume</a>
    <a href="portfolio.html">Portfolio</a>
    <a href="achievements.html">Achievements</a>
    <a href="contact.html">Contact</a>
  </nav>

  <!-- =========================
       PORTFOLIO CONTENT
       ========================= -->

  <main class="portfolio-page">

    <!-- =========================
         RESEARCH INTERNSHIP
         ========================= -->

    <section class="portfolio-section">

      <h2>Research Internship</h2>
      <div class="subtitle">
        LLM-based grading and feedback analysis for AI and Computer Vision exams
      </div>

      <h3>Context</h3>
      <p>
        This research internship focused on evaluating the feasibility of using
        Large Language Models (LLMs) for automated grading and feedback generation
        in university-level technical exams, particularly in Artificial Intelligence,
        Computer Vision, and LLM-related coursework.
      </p>

      <h3>Problem Statement</h3>
      <p>
        Manual grading of open-ended technical exams is time-consuming,
        subjective, and difficult to scale. The core challenge was to assess
        whether modern LLMs can reliably evaluate student answers, assign
        consistent scores, and generate meaningful feedback—without compromising
        fairness, correctness, or pedagogical value.
      </p>

      <h3>Approach</h3>
      <ul>
        <li>Designed structured prompts for grading and feedback generation</li>
        <li>Tested multiple LLM configurations across diverse exam questions</li>
        <li>Compared model outputs against predefined grading criteria</li>
        <li>Analyzed consistency, failure cases, and hallucination patterns</li>
      </ul>

      <h3>Key Explorations</h3>
      <ul>
        <li>Prompt engineering strategies for grading versus feedback tasks</li>
        <li>Model sensitivity to question phrasing and answer structure</li>
        <li>Differences between numerical scoring and qualitative feedback</li>
        <li>Limitations of LLMs in mathematical and vision-related reasoning</li>
      </ul>

      <h3>Impact & Findings</h3>
      <p>
        The study demonstrated strong LLM performance for structured,
        concept-based answers while revealing reduced reliability for visually
        grounded or mathematically intensive tasks. Results highlighted the
        importance of prompt design and rubric clarity, directly informing future
        research directions in AI-assisted assessment and feedback systems.
      </p>

      <h3>Focus Areas & Skills</h3>
      <ul>
        <li>Large Language Models (LLMs)</li>
        <li>Prompt Engineering for Evaluation</li>
        <li>AI-assisted Grading & Feedback Systems</li>
        <li>Model Behavior and Failure Analysis</li>
        <li>Research-oriented Experimentation</li>
        <li>Technical Analysis and Documentation</li>
      </ul>

      <div class="divider"></div>

    </section>
    <section class="portfolio-section">
      <h2>Document & Web RAG Q&amp;A (Open-Source LLM)</h2>
      <p class="subtitle">
        An interactive Retrieval-Augmented Generation demo that answers questions grounded in uploaded PDFs/DOCX, pasted text, or a web URL.
      </p>

      <h3>Context</h3>
      <p>
        Independent project built end-to-end and deployed as a live demo. Focused on practical AI engineering: retrieval, grounding, and user-facing interaction.
      </p>

      <h3>Problem</h3>
      <p>
        LLMs can produce confident but incorrect answers when they don’t have access to up-to-date or private information. I wanted a system that can
        reliably answer questions using <em>only</em> user-provided sources (documents or web pages), with clear grounding in retrieved context.
      </p>

      <h3>Approach</h3>
      <ul>
        <li><strong>Ingestion:</strong> Accepts PDF/DOCX uploads, raw text input, or a web link and extracts clean text for indexing.</li>
        <li><strong>Chunking:</strong> Splits text into overlapping chunks to preserve context and improve retrieval recall.</li>
        <li><strong>Embeddings + Vector Search:</strong> Generates sentence embeddings and stores them in a FAISS vector index for fast similarity search.</li>
        <li><strong>Retrieval-Augmented Answering:</strong> Retrieves the most relevant chunks and answers strictly from that context to reduce hallucinations.</li>
        <li><strong>Frontend:</strong> Deployed as a Gradio web app on Hugging Face Spaces for a simple, user-friendly demo workflow.</li>
      </ul>

      <h3>Impact</h3>
      <ul>
        <li>Delivers grounded Q&amp;A over user-provided documents and web content without requiring paid APIs.</li>
        <li>Provides a live, interactive demo suitable for recruiter review (upload → ask → answer).</li>
        <li>Demonstrates end-to-end AI system building: data ingestion, retrieval, and production-style deployment.</li>
      </ul>

      <h3>Skills</h3>
      <ul>
        <li>RAG system design (chunking strategies, retrieval, grounding)</li>
        <li>Vector databases / similarity search (FAISS)</li>
        <li>Embeddings (Sentence Transformers)</li>
        <li>LLM integration and safe answer constraints</li>
        <li>Deployment and MLOps fundamentals (Hugging Face Spaces)</li>
      </ul>

      <p>
        <a href="https://huggingface.co/spaces/KavithaL4/rag-web-data-demo-1" target="_blank" rel="noopener noreferrer">
          Live Demo (Hugging Face Space)
        </a>
      </p>
    </section>

    <!-- Independent projects will go BELOW this later -->
    <!-- Master’s thesis will go ABOVE this later -->

  </main>

  <!-- =========================
       MOBILE MENU SCRIPT
       ========================= -->

  <script>
    const hamburger = document.getElementById("hamburger");
    const mobileMenu = document.getElementById("mobileMenu");
    const closeMenu = document.getElementById("closeMenu");

    hamburger.addEventListener("click", (e) => {
      e.stopPropagation();
      mobileMenu.classList.toggle("open");
    });

    closeMenu.addEventListener("click", () => {
      mobileMenu.classList.remove("open");
    });

    document.addEventListener("click", (e) => {
      if (
        mobileMenu.classList.contains("open") &&
        !mobileMenu.contains(e.target) &&
        e.target !== hamburger
      ) {
        mobileMenu.classList.remove("open");
      }
    });
  </script>

</body>
</html>
